{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa43832e-146b-40ad-af2a-fa097437893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11504fcf-620b-45fe-85d7-78ff61d6ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98b9e9e-dec1-490c-bf0e-fcbe506a9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_night = 'day' # choices 'night' , 'day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b7ce98-2769-41cd-9abb-665239715575",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "train_num_steps = 70000\n",
    "timesteps = 1000\n",
    "path_to_data = f'../../data/separated_night_day/{day_night}/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4393efe-0198-48bb-bb67-658800aefa0a",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3063d1e7-bd0f-41dd-88e5-614d7b798f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class DayNightDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads 64×64 RGB images from\n",
    "        ../../data/separated_night_day/{day_night}/train\n",
    "    or any similar folder that just contains .png/.jpg files.\n",
    "    \"\"\"\n",
    "    _valid_ext = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir  = root_dir\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        self.image_paths = sorted(\n",
    "            p for p in os.listdir(root_dir)\n",
    "            if p.lower().endswith(self._valid_ext)\n",
    "        )\n",
    "        if not self.image_paths:\n",
    "            raise RuntimeError(f'No images found in {root_dir}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        img = Image.open(img_path).convert('RGB')      # keep 3 channels\n",
    "        return self.transform(img)                     # → [3,64,64] float in [0,1]\n",
    "\n",
    "\n",
    "def get_daynight_loaders(day_night,\n",
    "                         data_root='../../data/separated_night_day',\n",
    "                         batch_size=32,\n",
    "                         val_split=0.1,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=False,\n",
    "                         seed=None,\n",
    "                         transform=None):\n",
    "    \"\"\"\n",
    "    Returns (train_loader, val_loader) for either 'day' or 'night'.\n",
    "    \"\"\"\n",
    "\n",
    "    path_to_data = os.path.join(data_root, day_night, 'train')\n",
    "    dataset = DayNightDataset(path_to_data,\n",
    "                              transform=transform or transforms.ToTensor())\n",
    "\n",
    "    # ── train / val split ────────────────────────────────────────────\n",
    "    val_len = int(len(dataset) * val_split)\n",
    "    train_len = len(dataset) - val_len\n",
    "    if seed is not None:\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "        train_ds, val_ds = random_split(dataset, [train_len, val_len],\n",
    "                                        generator=generator)\n",
    "    else:\n",
    "        train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    kwargs = dict(num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    train_loader = DataLoader(train_ds,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              **kwargs)\n",
    "    val_loader   = DataLoader(val_ds,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              **kwargs)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6bbf7-c3f2-4ae1-a98d-55c87a16a2d1",
   "metadata": {},
   "source": [
    "# Train DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3aaf2f-aa3f-45d0-9fb5-756e09db9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "mults = (1, 2, 4)\n",
    "mults_str = '_'.join(str(m) for m in mults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888e3100-b4e4-4bc6-a8cb-d66dfe933fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: night‑only training set\n",
    "train_loader, val_loader = get_daynight_loaders(\n",
    "    day_night=day_night,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),          # scale to [0,1]\n",
    "        # add your own flips / colour jitter here if you like\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b5988-8085-4d6e-b4cc-3b14bac40d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70000 [00:00<?, ?it/s]/NAS/PROJECTS/BOMRGD/envs/ddpm_env/lib/python3.8/contextlib.py:83: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "loss: 0.0449:   2%|▏         | 1584/70000 [11:10<7:56:46,  2.39it/s] "
     ]
    }
   ],
   "source": [
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults =mults, \n",
    "    flash_attn = True\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 64,\n",
    "    timesteps = timesteps,           # number of steps\n",
    "    sampling_timesteps = 250    # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    ")\n",
    "results_folder = f'./results/{day_night}/{mults_str}/tr_stp_{train_num_steps}_stp{timesteps}/{date_time}'\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    path_to_data,\n",
    "    train_batch_size = 32,\n",
    "    train_lr = 8e-5,\n",
    "    train_num_steps = train_num_steps,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = True,                       # turn on mixed precision\n",
    "    calculate_fid = False,              # whether to calculate fid during training\n",
    "    results_folder = results_folder,\n",
    "    save_and_sample_every = train_num_steps//10,\n",
    "    dl = train_loader,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d127f1e-612a-4304-b44f-88563e7cef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_night = 'night' # choices 'night' , 'day'\n",
    "date_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "train_num_steps = 70000\n",
    "timesteps = 1000\n",
    "path_to_data = f'../../data/separated_night_day/{day_night}/train'\n",
    "# example: night‑only training set\n",
    "train_loader, val_loader = get_daynight_loaders(\n",
    "    day_night=day_night,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),          # scale to [0,1]\n",
    "        # add your own flips / colour jitter here if you like\n",
    "    ])\n",
    ")\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults =mults, \n",
    "    flash_attn = True\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 64,\n",
    "    timesteps = timesteps,           # number of steps\n",
    "    sampling_timesteps = 250    # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    ")\n",
    "results_folder = f'./results/{day_night}/{mults_str}/tr_stp_{train_num_steps}_stp{timesteps}/{date_time}'\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    path_to_data,\n",
    "    train_batch_size = 32,\n",
    "    train_lr = 8e-5,\n",
    "    train_num_steps = train_num_steps,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = True,                       # turn on mixed precision\n",
    "    calculate_fid = False,              # whether to calculate fid during training\n",
    "    results_folder = results_folder,\n",
    "    save_and_sample_every = train_num_steps//10,\n",
    "    dl = train_loader,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcc661-8e7a-41de-b43e-87e85d6aa8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm_env",
   "language": "python",
   "name": "ddpm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
